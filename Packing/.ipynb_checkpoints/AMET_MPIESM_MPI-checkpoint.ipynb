{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Computing AMET with Surface & TOA flux** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2019.08.09 ** <br>\n",
    "** Last Update  : 2019.09.09 ** <br>\n",
    "Description     : This notebook aims to compute AMET with TOA/surface flux fields from NorESM model. The NorESM model is launched by NERSC in Blue Action Work Package 3 as coordinated experiments for joint analysis. It contributes to the Deliverable 3.1. <br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The fields used here are post-processed monthly mean fields. Hence there is no accumulation that need to be taken into account.<br>\n",
    "\n",
    "The **positive sign** for each variable varies:<br>\n",
    "* Latent heat flux (LHF) - downward <br>\n",
    "* Sensible heat flux (SHF) - downward <br>\n",
    "* Net solar radiation flux at TOA (NTopSol & UTopSol) - downward <br>\n",
    "* Net solar radiation flux at surface (NSurfSol) - downward <br>\n",
    "* Net longwave radiation flux at surface (NSurfTherm) - downward <br>\n",
    "* Net longwave radiation flux at TOA (OLR) - downward <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/ESLT0068/NLeSC/Computation_Modeling/Bjerknes/Scripts/META\")\n",
    "import scipy as sp\n",
    "import pygrib\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os\n",
    "import meta.statistics\n",
    "import meta.visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2264670,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  ######################################\n",
    "# specify starting and ending time\n",
    "start_year = 1979\n",
    "end_year = 2013\n",
    "# specify data path\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/MPIESM_MPI'\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/AMET_netCDF'\n",
    "# ensemble number\n",
    "ensemble = 10\n",
    "# experiment number\n",
    "exp = 4\n",
    "# example file\n",
    "#datapath_example = os.path.join(datapath, 'SHF', 'Amon2d_amip_bac_rg_1_SHF_1979-2013.grb')\n",
    "#datapath_example = os.path.join(datapath, 'LHF', 'Amon2d_amip_bac_rg_1_LHF_1979-2013.grb')\n",
    "#datapath_example = os.path.join(datapath, 'NSurfSol', 'Amon2d_amip_bac_rg_1_NSurfSol_1979-2014.grb')\n",
    "#datapath_example = os.path.join(datapath, 'NTopSol', 'Amon2d_amip_bac_rg_1_DTopSol_1979-2014.grb')\n",
    "#datapath_example = os.path.join(datapath, 'UTopSol', 'Amon2d_amip_bac_rg_1_UTopSol_1979-2014.grb')\n",
    "#datapath_example = os.path.join(datapath, 'NSurfTherm', 'Amon2d_amip_bac_rg_1_NSurfTherm_1979-2014.grb')\n",
    "datapath_example = os.path.join(datapath, 'OLR', 'Amon2d_amip_bac_rg_1_OLR_1979-2014.grb')\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, exp_num, ensemble_num):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets of experiment {} ensemble number {}\".format(exp_num+1, ensemble_num))\n",
    "    # get data path\n",
    "    if exp_num == 0 : # exp 1\n",
    "        datapath_slhf = os.path.join(datapath, 'LHF', 'Amon2d_amip_bac_rg_{}_LHF_1979-2013.grb'.format(ensemble_num))\n",
    "        datapath_sshf = os.path.join(datapath, 'SHF', 'Amon2d_amip_bac_rg_{}_SHF_1979-2013.grb'.format(ensemble_num))\n",
    "        datapath_ssr = os.path.join(datapath, 'NSurfSol', 'Amon2d_amip_bac_rg_{}_NSurfSol_1979-2014.grb'.format(ensemble_num))\n",
    "        datapath_str = os.path.join(datapath, 'NSurfTherm', 'Amon2d_amip_bac_rg_{}_NSurfTherm_1979-2014.grb'.format(ensemble_num))\n",
    "        datapath_tsr_in = os.path.join(datapath, 'NTopSol', 'Amon2d_amip_bac_rg_{}_DTopSol_1979-2014.grb'.format(ensemble_num))\n",
    "        datapath_tsr_out = os.path.join(datapath, 'UTopSol', 'Amon2d_amip_bac_rg_{}_UTopSol_1979-2014.grb'.format(ensemble_num))\n",
    "        datapath_ttr = os.path.join(datapath, 'OLR', 'Amon2d_amip_bac_rg_{}_OLR_1979-2014.grb'.format(ensemble_num))\n",
    "    elif exp_num == 1:\n",
    "        datapath_slhf = os.path.join(datapath, 'LHF', 'Amon2d_amip_bac_exp{}_rg_{}_LHF_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_sshf = os.path.join(datapath, 'SHF', 'Amon2d_amip_bac_exp{}_rg_{}_SHF_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_ssr = os.path.join(datapath, 'NSurfSol', 'Amon2d_amip_bac_exp{}_rg_{}_NSurfSol_1979-2014.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_str = os.path.join(datapath, 'NSurfTherm', 'Amon2d_amip_bac_exp{}_rg_{}_NSurfTherm_1979-2014.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_tsr_in = os.path.join(datapath, 'NTopSol', 'Amon2d_amip_bac_exp{}_rg_{}_DTopSol_1979-2014.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_tsr_out = os.path.join(datapath, 'UTopSol', 'Amon2d_amip_bac_exp{}_rg_{}_UTopSol_1979-2014.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_ttr = os.path.join(datapath, 'OLR', 'Amon2d_amip_bac_exp{}_rg_{}_OLR_1979-2014.grb'.format(exp_num+1, ensemble_num))\n",
    "    else:\n",
    "        datapath_slhf = os.path.join(datapath, 'LHF', 'Amon2d_amip_bac_exp{}_rg_{}_LHF_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_sshf = os.path.join(datapath, 'SHF', 'Amon2d_amip_bac_exp{}_rg_{}_SHF_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_ssr = os.path.join(datapath, 'NSurfSol', 'Amon2d_amip_bac_exp{}_rg_{}_NSurfSol_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_str = os.path.join(datapath, 'NSurfTherm', 'Amon2d_amip_bac_exp{}_rg_{}_NSurfTherm_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_tsr_in = os.path.join(datapath, 'NTopSol', 'Amon2d_amip_bac_exp{}_rg_{}_DTopSol_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_tsr_out = os.path.join(datapath, 'UTopSol', 'Amon2d_amip_bac_exp{}_rg_{}_UTopSol_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "        datapath_ttr = os.path.join(datapath, 'OLR', 'Amon2d_amip_bac_exp{}_rg_{}_OLR_1979-2013.grb'.format(exp_num+1, ensemble_num))\n",
    "                \n",
    "    # get the variable keys    \n",
    "    grbs_slhf =  pygrib.open(datapath_slhf)\n",
    "    grbs_sshf = pygrib.open(datapath_sshf)\n",
    "    grbs_ssr = pygrib.open(datapath_ssr)\n",
    "    grbs_str = pygrib.open(datapath_str)\n",
    "    grbs_tsr_in = pygrib.open(datapath_tsr_in)\n",
    "    grbs_tsr_out = pygrib.open(datapath_tsr_out)\n",
    "    grbs_ttr = pygrib.open(datapath_ttr)\n",
    "\n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return grbs_slhf, grbs_sshf, grbs_ssr, grbs_str, grbs_tsr_in, grbs_tsr_out, grbs_ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amet(grbs_slhf, grbs_sshf, grbs_ssr, grbs_str, grbs_tsr_in,\n",
    "         grbs_tsr_out, grbs_ttr, period_1979_2013, lat, lon):\n",
    "    # get all the varialbes\n",
    "    # make sure we know the sign of all the input variables!!!\n",
    "    # ascending lat\n",
    "    var_slhf = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float) # surface latent heat flux W/m2\n",
    "    var_sshf = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float) # surface sensible heat flux W/m2 \n",
    "    var_ssr = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "    var_str = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "    var_tsr_in = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "    var_tsr_out = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "    var_ttr = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "    # load data\n",
    "    counter = 1\n",
    "    for i in np.arange(len(period_1979_2013)*12):\n",
    "        key_slhf = grbs_slhf.message(counter)\n",
    "        key_sshf = grbs_sshf.message(counter)\n",
    "        key_ssr = grbs_ssr.message(counter)\n",
    "        key_str = grbs_str.message(counter)\n",
    "        key_tsr_in = grbs_tsr_in.message(counter)\n",
    "        key_tsr_out = grbs_tsr_out.message(counter)\n",
    "        key_ttr = grbs_ttr.message(counter)\n",
    "        \n",
    "        var_slhf[i,:,:] = key_slhf.values\n",
    "        var_sshf[i,:,:] = key_sshf.values\n",
    "        var_ssr[i,:,:] = key_ssr.values\n",
    "        var_str[i,:,:] = key_str.values\n",
    "        var_tsr_in[i,:,:] = key_tsr_in.values\n",
    "        var_tsr_out[i,:,:] = key_tsr_out.values\n",
    "        var_ttr[i,:,:] = key_ttr.values\n",
    "        \n",
    "        # counter update\n",
    "        counter +=1\n",
    "    \n",
    "    #size of the grid box\n",
    "    dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * lat /\n",
    "                                            360) / len(lon) \n",
    "    dy = np.pi * constant['R'] / len(lat)\n",
    "    # calculate total net energy flux at TOA/surface\n",
    "    net_flux_surf = var_slhf + var_sshf + var_ssr + var_str\n",
    "    net_flux_toa = var_tsr_in + var_tsr_out + var_ttr\n",
    "    net_flux_surf_area = np.zeros(net_flux_surf.shape, dtype=float) # unit W\n",
    "    net_flux_toa_area = np.zeros(net_flux_toa.shape, dtype=float)\n",
    "\n",
    "    grbs_slhf.close()\n",
    "    grbs_sshf.close()\n",
    "    grbs_ssr.close()\n",
    "    grbs_str.close()\n",
    "    grbs_tsr_in.close()\n",
    "    grbs_tsr_out.close()\n",
    "    grbs_ttr.close()\n",
    "    \n",
    "    for i in np.arange(len(lat)):\n",
    "        # change the unit to terawatt\n",
    "        net_flux_surf_area[:,i,:] = net_flux_surf[:,i,:]* dx[i] * dy / 1E+12\n",
    "        net_flux_toa_area[:,i,:] = net_flux_toa[:,i,:]* dx[i] * dy / 1E+12\n",
    "    \n",
    "    # take the zonal integral of flux\n",
    "    net_flux_surf_int = np.sum(net_flux_surf_area,2) / 1000 # PW\n",
    "    net_flux_toa_int = np.sum(net_flux_toa_area,2) / 1000\n",
    "    # AMET as the residual of net flux at TOA & surface\n",
    "    AMET_res_ERAI = np.zeros(net_flux_surf_int.shape)\n",
    "    for i in np.arange(len(lat)):\n",
    "        AMET_res_ERAI[:,i] = -(np.sum(net_flux_toa_int[:,0:i+1],1) -\n",
    "                                np.sum(net_flux_surf_int[:,0:i+1],1))\n",
    "    AMET_res_ERAI = AMET_res_ERAI.reshape(-1,12,len(lat))\n",
    "    return AMET_res_ERAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_point (pool_amet, lat, output_path, exp):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    #logging.info(\"Start creating netcdf file for the 2D fields of ERAI at each grid point.\")\n",
    "    # get the basic dimensions\n",
    "    ens, year, month, _ = pool_amet.shape\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path, 'amet_MPIESM_MPI_exp{}.nc'.format(exp+1)),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    ens_wrap_dim = data_wrap.createDimension('ensemble', ens)\n",
    "    year_wrap_dim = data_wrap.createDimension('year', year)\n",
    "    month_wrap_dim = data_wrap.createDimension('month', month)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(lat))\n",
    "    # create coordinate variable\n",
    "    ens_wrap_var = data_wrap.createVariable('ensemble',np.int32,('ensemble',))\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    month_wrap_var = data_wrap.createVariable('month',np.int32,('month',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    # create the actual 4d variable\n",
    "    amet_wrap_var = data_wrap.createVariable('amet',np.float64,('ensemble','year','month','latitude'),zlib=True)  \n",
    "    # global attributes\n",
    "    data_wrap.description = 'Monthly mean atmospheric meridional energy transport'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    amet_wrap_var.units = 'PW'\n",
    "    amet_wrap_var.long_name = 'atmospheric meridional energy transport'\n",
    "    # writing data\n",
    "    ens_wrap_var[:] = np.arange(ens)\n",
    "    month_wrap_var[:] = np.arange(month)+1\n",
    "    year_wrap_var[:] = np.arange(year)+1979\n",
    "    lat_wrap_var[:] = lat\n",
    "\n",
    "    amet_wrap_var[:] = pool_amet\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"The generation of netcdf files is complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start retrieving datasets of experiment 1 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "The generation of netcdf files is complete!!\n",
      "Packing AMET is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n",
      "Start retrieving datasets of experiment 2 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "The generation of netcdf files is complete!!\n",
      "Packing AMET is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n",
      "Start retrieving datasets of experiment 3 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 3 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "The generation of netcdf files is complete!!\n",
      "Packing AMET is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n",
      "Start retrieving datasets of experiment 4 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 4 ensemble number 7\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno could not open %s] /home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/MPIESM_MPI/SHF/Amon2d_amip_bac_exp4_rg_7_SHF_1979-2013.grb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-63cf2d53d9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# get variable keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mgrbs_slhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_sshf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_ssr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_tsr_in\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mgrbs_tsr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_ttr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_key_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m# compute amet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpool_amet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrbs_slhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_sshf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_ssr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_tsr_in\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mgrbs_tsr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrbs_ttr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_1979_2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-71e0f8b8a6cc>\u001b[0m in \u001b[0;36mvar_key_retrieve\u001b[0;34m(datapath, exp_num, ensemble_num)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# get the variable keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mgrbs_slhf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpygrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_slhf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mgrbs_sshf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_sshf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mgrbs_ssr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_ssr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mgrbs_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygrib.pyx\u001b[0m in \u001b[0;36mpygrib.open.__cinit__ (pygrib.c:2947)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno could not open %s] /home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/MPIESM_MPI/SHF/Amon2d_amip_bac_exp4_rg_7_SHF_1979-2013.grb"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    ensemble_list = ['01','02','03','04','05','06','07','08','09','10',\n",
    "                     '11','12','13','14','15','16','17','18','19','20',\n",
    "                     '21','22','23','24','25','26','27','28','29','30',]\n",
    "    # index of months\n",
    "    period_1979_2013 = np.arange(start_year,end_year+1,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get basic dimensions from sample file\n",
    "    grbs_example = pygrib.open(datapath_example)\n",
    "    key_example = grbs_example.message(1)\n",
    "    lats, lons = key_example.latlons()\n",
    "    lat = lats[:,0]\n",
    "    lon = lons[0,:]\n",
    "    grbs_example.close()\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year_1979_2013 = len(period_1979_2013)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_latitude = len(lat)\n",
    "    Dim_longitude = len(lon)\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # loop for calculation \n",
    "    for i in range(exp):\n",
    "        pool_amet = np.zeros((ensemble,Dim_year_1979_2013,Dim_month,Dim_latitude),dtype = float)\n",
    "        for j in range(ensemble):\n",
    "            # get variable keys\n",
    "            grbs_slhf, grbs_sshf, grbs_ssr, grbs_str, grbs_tsr_in,\\\n",
    "            grbs_tsr_out, grbs_ttr = var_key_retrieve(datapath, i, j)\n",
    "            # compute amet\n",
    "            pool_amet[j,:,:,:] = amet(grbs_slhf, grbs_sshf, grbs_ssr, grbs_str, grbs_tsr_in,\\\n",
    "                                      grbs_tsr_out, grbs_ttr, period_1979_2013, lat, lon)              \n",
    "        ####################################################################\n",
    "        ######                 Data Wrapping (NetCDF)                #######\n",
    "        ####################################################################\n",
    "        # save netcdf\n",
    "        create_netcdf_point(pool_amet, lat, output_path, i)\n",
    "        print ('Packing AMET is complete!!!')\n",
    "        print ('The output is in sleep, safe and sound!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############################################################################\n",
    "# first check\n",
    "grbs_example = pygrib.open(datapath_example)\n",
    "key_example = grbs_example.message(1)\n",
    "lats, lons = key_example.latlons()\n",
    "lat = lats[:,0]\n",
    "lon = lons[0,:]\n",
    "print(lat)\n",
    "print(lon)\n",
    "#k = key_example.values\n",
    "#print(k[30:40,330:340])\n",
    "#print(key_example.unit)\n",
    "# print all the credentials\n",
    "#for i in grbs_example:\n",
    "#    print(i)\n",
    "grbs_example.close()\n",
    "\n",
    "# index of months\n",
    "period_1979_2013 = np.arange(start_year,end_year+1,1)\n",
    "\n",
    "values = np.zeros((len(period_1979_2013)*12,len(lat),len(lon)),dtype=float)\n",
    "counter = 1\n",
    "\n",
    "grbs_example = pygrib.open(datapath_example)\n",
    "\n",
    "for i in np.arange(len(period_1979_2013)*12):\n",
    "    key = grbs_example.message(counter)\n",
    "    values[i,:,:] = key.values\n",
    "    counter +=1\n",
    "    \n",
    "value_max = np.amax(values)\n",
    "value_min = np.amin(values)\n",
    "\n",
    "print(value_max)\n",
    "print(value_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

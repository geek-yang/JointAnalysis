{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright Netherlands eScience Center <br>\n",
    "** Function     : Computing AMET with Surface & TOA flux** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2018.09.09 ** <br>\n",
    "** Last Update  : 2018.09.09 ** <br>\n",
    "Description     : This notebook aims to compute AMET with TOA/surface flux fields from EC Earth model. The EC-Earth model is launched by DMI in Blue Action Work Package 3 as coordinated experiments for joint analysis. It contributes to the Deliverable 3.1. <br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The fields used here are post-processed monthly mean fields. Hence there is no accumulation that need to be taken into account.<br>\n",
    "\n",
    "Since EC-Earth is built on ECMWF IFS. The definition of variables are the same. This means for all the flux used here, downward is positive. The **positive sign** for each variable varies:<br>\n",
    "* Latent heat flux (slhf) - downward (-428 to 20) <br>\n",
    "* Sensible heat flux (sshf) - downward (-248 to 62) <br>\n",
    "* Net solar radiation flux at TOA (tsr) - downward (0 to 448) <br>\n",
    "* Net solar radiation flux at surface (ssr) - downward (0 to 363) <br>\n",
    "* Net longwave radiation flux at surface (str) - downward (-175 to -2) <br>\n",
    "* Net longwave radiation flux at TOA (ttr) - downward (-341 to -114) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"/home/ESLT0068/NLeSC/Computation_Modeling/Bjerknes/Scripts/META\")\n",
    "import scipy as sp\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os\n",
    "import meta.statistics\n",
    "import meta.visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2264670,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  ######################################\n",
    "# specify starting and ending time\n",
    "start_year = 1979\n",
    "end_year = 2015\n",
    "# specify data path\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/ECEarth_NLeSC'\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/AMET_netCDF'\n",
    "# ensemble number\n",
    "ensemble_12 = 1 #20\n",
    "ensemble_34 = 1\n",
    "# experiment number\n",
    "exp = 4\n",
    "name_list_exp = ['ITNV']\n",
    "# example file\n",
    "datapath_example = os.path.join(datapath, 'exp1', 'slhf',\n",
    "                                'ECE_ITNV_SLHF_monthly_1979_v2.nc')\n",
    "# factor for accumulated fields\n",
    "factor = 3600 * 3\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, Dim_year_1979_2015, Dim_latitude,\n",
    "                     Dim_longitude, exp_num, ensemble_num):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets of experiment {} ensemble number {}\".format(exp_num+1, ensemble_num))\n",
    "    # create space for data\n",
    "    var_slhf = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # surface latent heat flux W/m2\n",
    "    var_sshf = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # surface sensible heat flux W/m2 \n",
    "    var_ssr = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # surface solar radiation W/m2\n",
    "    var_str = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # surface thermal radiation W/m2\n",
    "    var_tsr = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # TOA solar radiation W/m2\n",
    "    var_ttr = np.zeros((Dim_year_1979_2015, 12, Dim_latitude, Dim_longitude),dtype=float) # TOA thermal radiation W/m2\n",
    "    for y in range(Dim_year_1979_2015):   \n",
    "        datapath_slhf = os.path.join(datapath, 'exp{}'.format(exp_num+1), 'slhf', 'ECE_{}_SLHF_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        datapath_sshf = os.path.join(datapath, 'exp{}'.format(exp_num+1),'sshf', 'ECE_{}_SSHF_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        datapath_ssr = os.path.join(datapath, 'exp{}'.format(exp_num+1),'ssr', 'ECE_{}_SSR_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        datapath_str = os.path.join(datapath, 'exp{}'.format(exp_num+1),'str', 'ECE_{}_STR_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        datapath_tsr = os.path.join(datapath, 'exp{}'.format(exp_num+1),'tsr', 'ECE_{}_TSR_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        datapath_ttr = os.path.join(datapath, 'exp{}'.format(exp_num+1),'ttr', 'ECE_{}_TTR_monthly_{}_v2.nc'.format(name_list_exp[ensemble_num],y+1979))\n",
    "        # get the variable keys            \n",
    "        # get the variable keys    \n",
    "        key_slhf = Dataset(datapath_slhf)\n",
    "        key_sshf = Dataset(datapath_sshf)\n",
    "        key_ssr = Dataset(datapath_ssr)\n",
    "        key_str = Dataset(datapath_str)\n",
    "        key_tsr = Dataset(datapath_tsr)\n",
    "        key_ttr = Dataset(datapath_ttr)\n",
    "        \n",
    "        var_slhf[y,:,:,:] = key_slhf.variables['SLHF'][:] # surface latent heat flux W/m2\n",
    "        var_sshf[y,:,:,:] = key_sshf.variables['SSHF'][:] # surface sensible heat flux W/m2 \n",
    "        var_ssr[y,:,:,:] = key_ssr.variables['SSR'][:] # surface solar radiation W/m2\n",
    "        var_str[y,:,:,:] = key_str.variables['STR'][:] # surface thermal radiation W/m2\n",
    "        var_tsr[y,:,:,:] = key_tsr.variables['TSR'][:] # TOA solar radiation W/m2\n",
    "        var_ttr[y,:,:,:] = key_ttr.variables['TTR'][:] # TOA thermal radiation W/m2\n",
    "        \n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return var_slhf, var_sshf, var_ssr, var_str, var_tsr, var_ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amet(var_slhf, var_sshf, var_ssr, var_str, var_tsr, var_ttr, lat, lon):\n",
    "    #size of the grid box\n",
    "    dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * lat /\n",
    "                                            360) / len(lon) \n",
    "    dy = np.pi * constant['R'] / len(lat)\n",
    "    # calculate total net energy flux at TOA/surface\n",
    "    net_flux_surf = var_slhf + var_sshf + var_ssr + var_str\n",
    "    net_flux_toa = var_tsr + var_ttr\n",
    "    net_flux_surf_area = np.zeros(net_flux_surf.shape, dtype=float) # unit W\n",
    "    net_flux_toa_area = np.zeros(net_flux_toa.shape, dtype=float)\n",
    "\n",
    "    for i in np.arange(len(lat)):\n",
    "        # change the unit to terawatt\n",
    "        net_flux_surf_area[:,:,i,:] = net_flux_surf[:,:,i,:]* dx[i] * dy / 1E+12\n",
    "        net_flux_toa_area[:,:,i,:] = net_flux_toa[:,:,i,:]* dx[i] * dy / 1E+12\n",
    "    \n",
    "    # take the zonal integral of flux\n",
    "    net_flux_surf_int = np.sum(net_flux_surf_area,3) / 1000 # PW\n",
    "    net_flux_toa_int = np.sum(net_flux_toa_area,3) / 1000\n",
    "    # AMET as the residual of net flux at TOA & surface\n",
    "    AMET_res_ERAI = np.zeros(net_flux_surf_int.shape)\n",
    "    for i in np.arange(len(lat)):\n",
    "        AMET_res_ERAI[:,:,i] = -(np.sum(net_flux_toa_int[:,:,0:i+1],2) -\n",
    "                                np.sum(net_flux_surf_int[:,:,0:i+1],2))\n",
    "    \n",
    "    return AMET_res_ERAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_point (pool_amet, lat, output_path, exp):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    #logging.info(\"Start creating netcdf file for the 2D fields of ERAI at each grid point.\")\n",
    "    # get the basic dimensions\n",
    "    ens, year, month, _ = pool_amet.shape\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path, 'amet_ECEarth_NLeSC_exp{}.nc'.format(exp+1)),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    ens_wrap_dim = data_wrap.createDimension('ensemble', ens)\n",
    "    year_wrap_dim = data_wrap.createDimension('year', year)\n",
    "    month_wrap_dim = data_wrap.createDimension('month', month)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(lat))\n",
    "    # create coordinate variable\n",
    "    ens_wrap_var = data_wrap.createVariable('ensemble',np.int32,('ensemble',))\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    month_wrap_var = data_wrap.createVariable('month',np.int32,('month',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    # create the actual 4d variable\n",
    "    amet_wrap_var = data_wrap.createVariable('amet',np.float64,('ensemble','year','month','latitude'),zlib=True)  \n",
    "    # global attributes\n",
    "    data_wrap.description = 'Monthly mean atmospheric meridional energy transport'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    amet_wrap_var.units = 'PW'\n",
    "    amet_wrap_var.long_name = 'atmospheric meridional energy transport'\n",
    "    # writing data\n",
    "    ens_wrap_var[:] = np.arange(ens)\n",
    "    month_wrap_var[:] = np.arange(month)+1\n",
    "    year_wrap_var[:] = np.arange(year)+1979\n",
    "    lat_wrap_var[:] = lat\n",
    "\n",
    "    amet_wrap_var[:] = pool_amet\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"The generation of netcdf files is complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start retrieving datasets of experiment 1 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "The generation of netcdf files is complete!!\n",
      "Packing AMET is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n",
      "Start retrieving datasets of experiment 2 ensemble number 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/ECEarth_NLeSC/exp2/slhf/ECE_ITNV_SLHF_monthly_1979_v2.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a9d887e703f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# get variable keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             var_slhf, var_sshf, var_ssr, var_str, var_tsr,            var_ttr = var_key_retrieve(datapath, Dim_year_1979_2015,\n\u001b[0;32m---> 38\u001b[0;31m                                        Dim_latitude, Dim_longitude, i, j)\n\u001b[0m\u001b[1;32m     39\u001b[0m             pool_amet_1979_2015[j,:,:,:] = amet(var_slhf, var_sshf, var_ssr,\n\u001b[1;32m     40\u001b[0m                                                 var_str, var_tsr, var_ttr, lat, lon)               \n",
      "\u001b[0;32m<ipython-input-4-231fcf35a53d>\u001b[0m in \u001b[0;36mvar_key_retrieve\u001b[0;34m(datapath, Dim_year_1979_2015, Dim_latitude, Dim_longitude, exp_num, ensemble_num)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# get the variable keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# get the variable keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mkey_slhf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_slhf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mkey_sshf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_sshf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mkey_ssr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath_ssr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/ECEarth_NLeSC/exp2/slhf/ECE_ITNV_SLHF_monthly_1979_v2.nc'"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    # index of months\n",
    "    period_1979_2015 = np.arange(start_year,end_year+1,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get basic dimensions from sample file\n",
    "    key_example = Dataset(datapath_example)\n",
    "    lat = key_example.variables['lat'][:] # ascending lat\n",
    "    lon = key_example.variables['lon'][:]\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year_1979_2015 = len(period_1979_2015)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_latitude = len(lat)\n",
    "    Dim_longitude = len(lon)\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # loop for calculation\n",
    "    for i in range(exp):\n",
    "        if i<2:\n",
    "            ensemble = ensemble_12\n",
    "            pool_amet_1979_2015 = np.zeros((ensemble,Dim_year_1979_2015,Dim_month,Dim_latitude),dtype = float)\n",
    "        \n",
    "        else:\n",
    "            ensemble = ensemble_34\n",
    "            pool_amet_1979_2015 = np.zeros((ensemble,Dim_year_1979_2015,Dim_month,Dim_latitude),dtype = float)\n",
    "        for j in range(ensemble):\n",
    "            # get variable keys\n",
    "            var_slhf, var_sshf, var_ssr, var_str, var_tsr,\\\n",
    "            var_ttr = var_key_retrieve(datapath, Dim_year_1979_2015,\n",
    "                                       Dim_latitude, Dim_longitude, i, j)\n",
    "            pool_amet_1979_2015[j,:,:,:] = amet(var_slhf, var_sshf, var_ssr,\n",
    "                                                var_str, var_tsr, var_ttr, lat, lon)               \n",
    "        ####################################################################\n",
    "        ######                 Data Wrapping (NetCDF)                #######\n",
    "        ####################################################################\n",
    "        # save netcdf\n",
    "        create_netcdf_point(pool_amet_1979_2015, lat, output_path, i)\n",
    "        print ('Packing AMET is complete!!!')\n",
    "        print ('The output is in sleep, safe and sound!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

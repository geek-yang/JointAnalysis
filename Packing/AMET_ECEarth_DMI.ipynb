{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Computing AMET with Surface & TOA flux** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2018.09.09 ** <br>\n",
    "** Last Update  : 2018.09.09 ** <br>\n",
    "Description     : This notebook aims to compute AMET with TOA/surface flux fields from EC Earth model. The EC-Earth model is launched by DMI in Blue Action Work Package 3 as coordinated experiments for joint analysis. It contributes to the Deliverable 3.1. <br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The fields used here are post-processed monthly mean fields. Hence there is no accumulation that need to be taken into account.<br>\n",
    "\n",
    "Since EC-Earth is built on ECMWF IFS. The definition of variables are the same. This means for all the flux used here, downward is positive. The **positive sign** for each variable varies:<br>\n",
    "* Latent heat flux - downward <br>\n",
    "* Sensible heat flux - downward <br>\n",
    "* Net solar radiation flux at TOA - downward <br>\n",
    "* Net solar radiation flux at surface - downward <br>\n",
    "* Net longwave radiation flux at surface - downward <br>\n",
    "* Net longwave radiation flux at TOA - downward <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/ESLT0068/NLeSC/Computation_Modeling/Bjerknes/Scripts/META\")\n",
    "import scipy as sp\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os\n",
    "import meta.statistics\n",
    "import meta.visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2264670,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  ######################################\n",
    "# specify starting and ending time\n",
    "start_year = 1979\n",
    "end_year = 2015\n",
    "# specify data path\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/ECEarth_DMI/ENS00_19'\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/AMET_netCDF'\n",
    "# ensemble number\n",
    "ensemble = 20\n",
    "# experiment number\n",
    "exp = 4\n",
    "# example file\n",
    "datapath_example = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP1-ENS1_1979-2015_2D_slhf.nc')\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, exp_num, ensemble_num):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets of experiment {} ensemble number {}\".format(exp_num+1, ensemble_num))\n",
    "    # get data path\n",
    "    if exp_num<2:\n",
    "        if ensemble_num<10:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_slhf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_sshf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ssr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_str.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_tsr = os.path.join(datapath, 'tsr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_tsr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ttr = os.path.join(datapath, 'ttr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ttr.nc'.format(exp_num+1, ensemble_num))\n",
    "        else:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_slhf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_sshf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ssr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_str.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_tsr = os.path.join(datapath, 'tsr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_tsr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ttr = os.path.join(datapath, 'ttr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ttr.nc4'.format(exp_num+1, ensemble_num))\n",
    "    else:\n",
    "        if ensemble_num<10:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_slhf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_sshf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ssr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_str.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_tsr = os.path.join(datapath, 'tsr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_tsr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ttr = os.path.join(datapath, 'ttr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ttr.nc'.format(exp_num+1, ensemble_num))\n",
    "        else:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_slhf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_sshf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ssr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_str.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_tsr = os.path.join(datapath, 'tsr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_tsr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ttr = os.path.join(datapath, 'ttr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ttr.nc4'.format(exp_num+1, ensemble_num))\n",
    "    # get the variable keys            \n",
    "    # get the variable keys    \n",
    "    key_slhf = Dataset(datapath_slhf)\n",
    "    key_sshf = Dataset(datapath_sshf)\n",
    "    key_ssr = Dataset(datapath_ssr)\n",
    "    key_str = Dataset(datapath_str)\n",
    "    key_tsr = Dataset(datapath_tsr)\n",
    "    key_ttr = Dataset(datapath_ttr)\n",
    "\n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return key_slhf, key_sshf, key_ssr, key_str, key_tsr, key_ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amet(key_slhf, key_sshf, key_ssr, key_str, key_tsr, key_ttr, lat, lon):\n",
    "    # get all the varialbes\n",
    "    # make sure that all the input variables here are positive downward!!!\n",
    "    var_slhf = key_slhf.variables['slhf'][:] # surface latent heat flux W/m2\n",
    "    var_sshf = key_sshf.variables['sshf'][:] # surface sensible heat flux W/m2 \n",
    "    var_ssr = key_ssr.variables['ssr'][:] # surface solar radiation W/m2\n",
    "    var_str = key_str.variables['str'][:] # surface thermal radiation W/m2\n",
    "    var_tsr = key_tsr.variables['tsr'][:] # TOA solar radiation W/m2\n",
    "    var_ttr = key_ttr.variables['ttr'][:] # TOA thermal radiation W/m2\n",
    "    #size of the grid box\n",
    "    dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * lat /\n",
    "                                            360) / len(lon) \n",
    "    dy = np.pi * constant['R'] / len(lat)\n",
    "    # calculate total net energy flux at TOA/surface\n",
    "    net_flux_surf = var_slhf + var_sshf + var_ssr + var_str\n",
    "    net_flux_toa = var_tsr + var_ttr\n",
    "    net_flux_surf_area = np.zeros(net_flux_surf.shape, dtype=float) # unit W\n",
    "    net_flux_toa_area = np.zeros(net_flux_toa.shape, dtype=float)\n",
    "\n",
    "    for i in np.arange(len(lat)):\n",
    "        # change the unit to terawatt\n",
    "        net_flux_surf_area[:,i,:] = net_flux_surf[:,i,:]* dx[i] * dy / 1E+12\n",
    "        net_flux_toa_area[:,i,:] = net_flux_toa[:,i,:]* dx[i] * dy / 1E+12\n",
    "    \n",
    "    # take the zonal integral of flux\n",
    "    net_flux_surf_int = np.sum(net_flux_surf_area,2) / 1000 # PW\n",
    "    net_flux_toa_int = np.sum(net_flux_toa_area,2) / 1000\n",
    "    # AMET as the residual of net flux at TOA & surface\n",
    "    AMET_res_ERAI = np.zeros(net_flux_surf_int.shape)\n",
    "    for i in np.arange(len(lat)):\n",
    "        AMET_res_ERAI[:,i] = -(np.sum(net_flux_toa_int[:,0:i+1],1) -\n",
    "                                np.sum(net_flux_surf_int[:,0:i+1],1))\n",
    "    AMET_res_ERAI = AMET_res_ERAI.reshape(-1,12,len(lat))\n",
    "    return AMET_res_ERAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_point (pool_amet, lat, output_path, exp):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    #logging.info(\"Start creating netcdf file for the 2D fields of ERAI at each grid point.\")\n",
    "    # get the basic dimensions\n",
    "    ens, year, month, _ = pool_amet.shape\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path, 'amet_ECEarth_DMI_exp{}.nc'.format(exp+1)),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    ens_wrap_dim = data_wrap.createDimension('ensemble', ens)\n",
    "    year_wrap_dim = data_wrap.createDimension('year', year)\n",
    "    month_wrap_dim = data_wrap.createDimension('month', month)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(lat))\n",
    "    # create coordinate variable\n",
    "    ens_wrap_var = data_wrap.createVariable('ensemble',np.int32,('ensemble',))\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    month_wrap_var = data_wrap.createVariable('month',np.int32,('month',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    # create the actual 4d variable\n",
    "    amet_wrap_var = data_wrap.createVariable('amet',np.float64,('ensemble','year','month','latitude'),zlib=True)  \n",
    "    # global attributes\n",
    "    data_wrap.description = 'Monthly mean atmospheric meridional energy transport'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    amet_wrap_var.units = 'PW'\n",
    "    amet_wrap_var.long_name = 'atmospheric meridional energy transport'\n",
    "    # writing data\n",
    "    ens_wrap_var[:] = np.arange(ens)\n",
    "    month_wrap_var[:] = np.arange(month)+1\n",
    "    year_wrap_var[:] = np.arange(year)+1979\n",
    "    lat_wrap_var[:] = lat\n",
    "\n",
    "    amet_wrap_var[:] = pool_amet\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"The generation of netcdf files is complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start retrieving datasets of experiment 1 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 10\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 11\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 12\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 13\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 14\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 15\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 16\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 17\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 18\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 19\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "The generation of netcdf files is complete!!\n",
      "Packing AMET is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n",
      "Start retrieving datasets of experiment 2 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 10\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 11\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 12\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 13\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 14\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 15\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 16\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 17\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 18\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 2 ensemble number 19\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    # index of months\n",
    "    period_1979_2015 = np.arange(start_year,end_year+1,1)\n",
    "    period_1979_2013 = np.arange(start_year,end_year+1-2,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get basic dimensions from sample file\n",
    "    key_example = Dataset(datapath_example)\n",
    "    lat = key_example.variables['lat'][:]\n",
    "    lon = key_example.variables['lon'][:]\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year_1979_2015 = len(period_1979_2015)\n",
    "    Dim_year_1979_2013 = len(period_1979_2013)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_latitude = len(lat)\n",
    "    Dim_longitude = len(lon)\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # data pool\n",
    "    pool_amet_1979_2015 = np.zeros((ensemble,Dim_year_1979_2015,Dim_month,Dim_latitude),dtype = float)\n",
    "    pool_amet_1979_2013 = np.zeros((ensemble,Dim_year_1979_2013,Dim_month,Dim_latitude),dtype = float)\n",
    "    # loop for calculation\n",
    "    for i in range(exp):\n",
    "        for j in range(ensemble):\n",
    "            # get variable keys\n",
    "            key_slhf, key_sshf, key_ssr, key_str, key_tsr,\\\n",
    "            key_ttr = var_key_retrieve(datapath, i, j)\n",
    "            # compute amet\n",
    "            if i<2:\n",
    "                pool_amet_1979_2015[j,:,:,:] = amet(key_slhf, key_sshf, key_ssr,\n",
    "                                                    key_str, key_tsr, key_ttr, lat, lon)\n",
    "            else:\n",
    "                pool_amet_1979_2013[j,:,:,:] = amet(key_slhf, key_sshf, key_ssr,\n",
    "                                                    key_str, key_tsr, key_ttr, lat, lon)                \n",
    "        ####################################################################\n",
    "        ######                 Data Wrapping (NetCDF)                #######\n",
    "        ####################################################################\n",
    "        # save netcdf\n",
    "        if i<2:\n",
    "            create_netcdf_point(pool_amet_1979_2015, lat, output_path, i)\n",
    "        else:\n",
    "            create_netcdf_point(pool_amet_1979_2013, lat, output_path, i)\n",
    "        print ('Packing AMET is complete!!!')\n",
    "        print ('The output is in sleep, safe and sound!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

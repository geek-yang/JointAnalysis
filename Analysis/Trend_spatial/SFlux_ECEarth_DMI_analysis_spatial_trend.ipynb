{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Analyze the trend of net surface flux from coordinated experiments**** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2019.08.09 ** <br>\n",
    "** Last Update  : 2019.08.29 ** <br>\n",
    "Description     : This notebook aims to analyze the trend of net surface flux from multiple coordinated experiments in Blue Action WP3. It contributes to the Deliverable 3.1. <br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The fields used here are post-processed monthly mean fields. It includes AMET from:\n",
    "* EC Earth (DMI)\n",
    "* CMCC-CM (CMCC)\n",
    "* WACCM6 (WHOI)\n",
    "* NorESM (NERSC)\n",
    "* HadGEM  (UoS)\n",
    "* EC Earth (NLeSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(\"/home/ESLT0068/NLeSC/Computation_Modeling/Bjerknes/Scripts/META\")\n",
    "import analyzer\n",
    "import visualizer\n",
    "import scipy as sp\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2264670,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model and Organization | Exp 1 | Exp 2 | Exp 3 | Exp 4 |    time   |\n",
    "|-----------------------|-------|-------|-------|-------|-----------|\n",
    "|    EC Earth (NLeSC)   |   20  |   20  |   20  |   20  | 1979-2015 (exp1&2) 1979-2013 (exp3&4) |\n",
    "|     EC Earth (DMI)    |   20  |   20  |   20  |   20  | 1979-2015 (exp1&2) 1979-2013 (exp3&4) |\n",
    "|     CMCC-CM (CMCC)    |   10  |   10  |   0   |   0   | 1979-2014 |\n",
    "|      WACCM6 (WHOI)    |   30  |   30  |   0   |   0   | 1979-2014 |\n",
    "|     NorESM (NERSC)    |   20  |   20  |   20  |   20  | 1979-2014 (exp1&2) 1979-2013 (exp3&4) |\n",
    "|     HadGEM  (UoS)     |   10  |   10  |   5   |   5   | 1979-2014 (exp1&2) 1979-2013 (exp3&4) |\n",
    "|   IAP-AGCM (IAP-NZC)  |   15  |   15  |   15  |   15  | 1979-2015 |\n",
    "|     IPSL-CM (CNRS)    |   30  |   30  |   20  |   20  | 1979-2014 |\n",
    "|      MPIESM (MPI)     |   10  |   10  |   5   |   5   | 1979-2015 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  ######################################\n",
    "# specify starting and ending time\n",
    "start_year = 1979\n",
    "end_year = 2015\n",
    "# specify data path\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_BlueAction_WP3/ECEarth_DMI/ENS00_19'\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/NLeSC/Computation_Modeling/BlueAction/WP3/JointAnalysis_AMET/AMIP/spatial'\n",
    "# ensemble number\n",
    "ensemble = 20\n",
    "# experiment number\n",
    "exp = 4\n",
    "# example file\n",
    "datapath_example = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP1-ENS1_1979-2015_2D_slhf.nc')\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, exp_num, ensemble_num):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets of experiment {} ensemble number {}\".format(exp_num+1, ensemble_num))\n",
    "    # get data path\n",
    "    if exp_num<2:\n",
    "        if ensemble_num<10:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_slhf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_sshf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ssr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_str.nc'.format(exp_num+1, ensemble_num))\n",
    "        else:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_slhf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_sshf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_ssr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2015_2D_str.nc4'.format(exp_num+1, ensemble_num))\n",
    "    else:\n",
    "        if ensemble_num<10:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_slhf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_sshf.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ssr.nc'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_str.nc'.format(exp_num+1, ensemble_num))\n",
    "        else:    \n",
    "            datapath_slhf = os.path.join(datapath, 'slhf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_slhf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_sshf = os.path.join(datapath, 'sshf', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_sshf.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_ssr = os.path.join(datapath, 'ssr', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_ssr.nc4'.format(exp_num+1, ensemble_num))\n",
    "            datapath_str = os.path.join(datapath, 'str', 'DMI_ecearth3_BA-WP3_AEXP{}-ENS{}_1979-2013_2D_str.nc4'.format(exp_num+1, ensemble_num))\n",
    "    # get the variable keys            \n",
    "    # get the variable keys    \n",
    "    key_slhf = Dataset(datapath_slhf)\n",
    "    key_sshf = Dataset(datapath_sshf)\n",
    "    key_ssr = Dataset(datapath_ssr)\n",
    "    key_str = Dataset(datapath_str)\n",
    "\n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return key_slhf, key_sshf, key_ssr, key_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sflux(key_slhf, key_sshf, key_ssr, key_str, lat, lon):\n",
    "    # get all the varialbes\n",
    "    # make sure that all the input variables here are positive downward!!!\n",
    "    var_slhf = key_slhf.variables['slhf'][:,:100,:] # surface latent heat flux W/m2\n",
    "    var_sshf = key_sshf.variables['sshf'][:,:100,:] # surface sensible heat flux W/m2 \n",
    "    var_ssr = key_ssr.variables['ssr'][:,:100,:] # surface solar radiation W/m2\n",
    "    var_str = key_str.variables['str'][:,:100,:] # surface thermal radiation W/m2\n",
    "    #size of the grid box\n",
    "    #dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * lat /\n",
    "    #                                        360) / len(lon) \n",
    "    #dy = np.pi * constant['R'] / len(lat)\n",
    "    # calculate total net energy flux at TOA/surface\n",
    "    net_flux_surf = var_slhf + var_sshf + var_ssr + var_str\n",
    "    net_flux_surf = net_flux_surf.reshape(-1,12,len(lat),len(lon))\n",
    "\n",
    "    return net_flux_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start retrieving datasets of experiment 1 ensemble number 0\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 1\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 2\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 3\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 4\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 5\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 6\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 7\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 8\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 9\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 10\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 11\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 12\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 13\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 14\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 15\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 16\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 17\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 18\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Start retrieving datasets of experiment 1 ensemble number 19\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Input array should have dimensions (year,month,lat,lon)\n",
      "The input data does not have the dimension of ensemble.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ESLT0068/NLeSC/Computation_Modeling/BlueAction/WP3/Scripts/JointAnalysis/Analysis/analyzer.py:434: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  a[i,j], b[i,j] = np.linalg.lstsq(A,series[:,i,j])[0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-69ccd39d3338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Trend of SFlux (W/(m2 year))'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             meta.visualizer.plots.geograph(lat, lon, ens_avg_DMI_exp._a,\n\u001b[0m\u001b[1;32m     56\u001b[0m                                            label, ticks, os.path.join(output_path,\n\u001b[1;32m     57\u001b[0m                                            'trend_spatial_ECEarth_DMI_SFlux_60N_exp_{}.png'.format(i)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    lat_DMI_20N = 100\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    ensemble_list = ['01','02','03','04','05','06','07','08','09','10',\n",
    "                     '11','12','13','14','15','16','17','18','19','20',\n",
    "                     '21','22','23','24','25','26','27','28','29','30',]\n",
    "    # index of months\n",
    "    period_1979_2015 = np.arange(start_year,end_year+1,1)\n",
    "    period_1979_2013 = np.arange(start_year,end_year+1-2,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get basic dimensions from sample file\n",
    "    key_example = Dataset(datapath_example)\n",
    "    lat = key_example.variables['lat'][:100]\n",
    "    lon = key_example.variables['lon'][:]\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year_1979_2015 = len(period_1979_2015)\n",
    "    Dim_year_1979_2013 = len(period_1979_2013)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_latitude = len(lat)\n",
    "    Dim_longitude = len(lon)\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # data pool\n",
    "    pool_sflux_1979_2015 = np.zeros((ensemble,Dim_year_1979_2015,Dim_month,Dim_latitude,Dim_longitude),dtype = float)\n",
    "    pool_sflux_1979_2013 = np.zeros((ensemble,Dim_year_1979_2013,Dim_month,Dim_latitude,Dim_longitude),dtype = float)\n",
    "    # loop for calculation\n",
    "    for i in range(exp):\n",
    "        for j in range(ensemble):\n",
    "            # get variable keys\n",
    "            key_slhf, key_sshf, key_ssr, key_str = var_key_retrieve(datapath, i, j)\n",
    "            # compute amet\n",
    "            if i<2:\n",
    "                pool_sflux_1979_2015[j,:,:,:,:] = sflux(key_slhf, key_sshf, key_ssr,\n",
    "                                                        key_str, lat, lon)\n",
    "            else:\n",
    "                pool_sflux_1979_2013[j,:,:,:,:] = sflux(key_slhf, key_sshf, key_ssr,\n",
    "                                                        key_str, lat, lon)\n",
    "        ####################################################################\n",
    "        ######        Calculating Trend   (positive downward)        #######\n",
    "        ####################################################################\n",
    "        if i<2:\n",
    "            # calculate trend and take ensemble mean\n",
    "            ens_avg_DMI_exp = analyzer.spatial(np.mean(pool_sflux_1979_2015[:],0))\n",
    "            ens_avg_DMI_exp.anomaly()\n",
    "            ens_avg_DMI_exp.trend()\n",
    "            #ticks = [-0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "            ticks = np.linspace(-0.5,0.5,11)\n",
    "            label = 'Trend of SFlux (W/(m2*decade))'\n",
    "            visualizer.plots.geograph(lat, lon, ens_avg_DMI_exp._a*10,\n",
    "                                      label, ticks, os.path.join(output_path,\n",
    "                                      'trend_spatial_ECEarth_DMI_SFlux_60N_exp_{}.png'.format(i)))\n",
    "        else:\n",
    "            ens_avg_DMI_exp = analyzer.spatial(np.mean(pool_sflux_1979_2013[:],0))\n",
    "            ens_avg_DMI_exp.anomaly()\n",
    "            ens_avg_DMI_exp.trend()\n",
    "            #ticks = [-0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "            ticks = np.linspace(-0.5,0.5,11)\n",
    "            label = 'Trend of SFlux (W/(m2*decade))'\n",
    "            visualizer.plots.geograph(lat, lon, ens_avg_DMI_exp._a*10,\n",
    "                                      label, ticks, os.path.join(output_path,\n",
    "                                      'trend_spatial_ECEarth_DMI_SFlux_60N_exp_{}.png'.format(i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
